# Comparatori UML

Sistema per confrontare modelli UML generati da LLM con modelli di riferimento. Utilizzato per le sperimentazioni della tesi sui diagrammi delle classi UML.


---

## Struttura del Progetto

```
Applicazione/
‚îú‚îÄ‚îÄ Back-end/                   # Codice sorgente principale
‚îÇ   ‚îú‚îÄ‚îÄ config.js               # ‚öôÔ∏è Configurazione esperimenti
‚îÇ   ‚îú‚îÄ‚îÄ prompt.js               # üìù Prompt per LLM (modificabile per RQ2)
‚îÇ   ‚îú‚îÄ‚îÄ index.js                # üöÄ Entry point principale
‚îÇ   ‚îú‚îÄ‚îÄ Logger.js               # üìä Sistema di logging
‚îÇ   ‚îú‚îÄ‚îÄ plantUML.js             # üìä Generatore PlantUML
‚îÇ   ‚îú‚îÄ‚îÄ LLM/                    # ü§ñ Provider di intelligenza artificiale
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Gemini.js           #   ‚Üí Integrazione Google Gemini
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OpenRouterIA.js     #   ‚Üí Integrazione OpenRouter (DeepSeek, Meta)
‚îÇ   ‚îú‚îÄ‚îÄ RQ1/                    # üî¨ Componenti core per Research Question 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Traccia.js          #   ‚Üí Elaborazione PDF delle tracce
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UmlAtteso.js        #   ‚Üí Parser file XMI di riferimento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ umlComparator.js    #   ‚Üí Algoritmi di confronto UML
‚îÇ   ‚îú‚îÄ‚îÄ RQ3/                    # üìã Research Question 3 - Error Reporting
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ErrorReporter.js    #   ‚Üí Sistema di report errori
‚îÇ   ‚îú‚îÄ‚îÄ RQ4/                    # üìä Research Question 4 - Validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Voto.js             #   ‚Üí Sistema di valutazione e metriche
‚îÇ   ‚îî‚îÄ‚îÄ .env                    # üîë API Keys (da creare)
‚îú‚îÄ‚îÄ Traccia/                    # üìÑ PDF delle tracce
‚îú‚îÄ‚îÄ UmlAtteso/                  # ‚úÖ XMI di riferimento (docente)
‚îú‚îÄ‚îÄ Sperimentazioni/            # üë• XMI degli studenti organizzati per traccia
‚îÇ   ‚îú‚îÄ‚îÄ Autobus/               #   ‚Üí Diagrammi studenti per traccia Autobus
‚îÇ   ‚îú‚îÄ‚îÄ Fotografia/            #   ‚Üí Diagrammi studenti per traccia Fotografia
‚îÇ   ‚îî‚îÄ‚îÄ ...                    #   ‚Üí Altre tracce
‚îú‚îÄ‚îÄ risultati/                  # üìà Log di output con timestamp
‚îî‚îÄ‚îÄ Prompt/                     # üìù Versioni storiche dei prompt
    ‚îú‚îÄ‚îÄ PromptFinale.txt        #   ‚Üí Prompt ottimizzato finale
    ‚îî‚îÄ‚îÄ promptIntermedio.txt    #   ‚Üí Versioni intermedie
```

---

## Quick Start

1. **Installa dipendenze**:
```bash
cd Back-end
npm install
```

2. **Configura API Keys** - Crea `.env`:
```env
GEMINI_API_KEY="la_tua_chiave_google_gemini"
openrouter_API_KEY="la_tua_chiave_openrouter"
```

3. **Ottieni le chiavi**:
   - **Gemini**: [Google AI Studio](https://makersuite.google.com/app/apikey) (gratuita)
   - **OpenRouter**: [OpenRouter.ai](https://openrouter.ai/) (a pagamento)

4. **Esegui**:
```bash
cd Back-end
npm start
# oppure
node index.js
```

---

## File di Configurazione Chiave

### üìÑ Back-end/config.js - Controllo Esperimenti
```javascript
export const experiment = "main";      // "main" o "Voto"
export const aiProvider = "gemini";    // "deepSeek", "gemini", "meta"  
export const pdfFile = "ToDo.pdf";     // File in Traccia/
export const xmiFile = "ToDo.xmi";     // File in UmlAtteso/
export const logFile = "ToDo";         // Prefisso per risultati/
export const directoryCampioni = "../Sperimentazioni/Autobus"; // Solo per "Voto"
```

### üìÑ Back-end/.env - API Keys
```env
GEMINI_API_KEY="la_tua_chiave_google_gemini"
openrouter_API_KEY="la_tua_chiave_openrouter"
```

### üìÑ Back-end/prompt.js - Template LLM
Contiene il prompt ottimizzato che viene inviato agli LLM. Modificabile per RQ2.

---

## Flussi di Lavoro

### üîÑ Modalit√† "main" - Singolo Confronto
1. **Traccia** ‚Üí `RQ1/Traccia.js` ‚Üí estrae testo da `Traccia/{pdfFile}`
2. **LLM** ‚Üí `LLM/{provider}.js` ‚Üí genera modello UML dalla traccia  
3. **Riferimento** ‚Üí `RQ1/UmlAtteso.js` ‚Üí carica modello da `UmlAtteso/{xmiFile}`
4. **Confronto** ‚Üí `RQ1/umlComparator.js` ‚Üí calcola similarit√† strutturale
5. **Report** ‚Üí `RQ3/ErrorReporter.js` ‚Üí classifica errori
6. **Output** ‚Üí `Logger.js` ‚Üí salva tutto in `risultati/`

### üìä Modalit√† "Voto" - Batch Analysis  
1. **Batch Studenti** ‚Üí elabora tutti gli XMI in `directoryCampioni`
2. **Valutazione** ‚Üí `RQ4/Voto.js` ‚Üí calcola metriche per ogni studente
3. **Modello LLM** ‚Üí genera modello AI dalla stessa traccia
4. **Confronto** ‚Üí confronta performance studenti vs AI
5. **Statistiche** ‚Üí media, migliore, peggiore performance

---

## Configurazione Esperimenti

### Parametri Principali (`Back-end/config.js`)

| Parametro | Valori | Descrizione |
|-----------|--------|-------------|
| `experiment` | `"main"`, `"Voto"` | Modalit√†: singolo confronto, batch studenti |
| `aiProvider` | `"deepSeek"`, `"gemini"`, `"meta"` | Modello LLM da utilizzare |
| `pdfFile` | `"Fotografia.pdf"` | Nome traccia in `Traccia/` |
| `xmiFile` | `"Fotografia.xmi"` | Nome modello atteso in `UmlAtteso/` |
| `logFile` | `"Fotografia"` | Prefisso file di output |
| `directoryCampioni` | `"../Sperimentazioni/Fotografia"` | Cartella XMI studenti (solo per "Voto") |
---

## Research Questions - Configurazioni Sperimentali

### RQ1: Confronto tra LLM
**Obiettivo**: Valutare come diversi modelli si comportano sulla stessa traccia  
**File coinvolti**: `Back-end/LLM/` (Gemini.js, OpenRouterIA.js), `Back-end/RQ1/`  
**Cosa cambia**: `aiProvider` (deepSeek ‚Üí gemini ‚Üí meta)  
**Cosa rimane fisso**: traccia, prompt, UML atteso

```javascript
// Test con DeepSeek
export const aiProvider = "deepSeek";
export const pdfFile = "Fotografia.pdf";
export const logFile = "RQ1_Fotografia_DeepSeek";

// Test con Gemini (cambia solo aiProvider)
export const aiProvider = "gemini";
export const pdfFile = "Fotografia.pdf";
export const logFile = "RQ1_Fotografia_Gemini";
```

### RQ2: Ottimizzazione Prompt
**Obiettivo**: Migliorare i risultati modificando solo il prompt  
**File coinvolti**: `Back-end/prompt.js`, `Prompt/` (versioni storiche)  
**Cosa cambia**: contenuto di `Back-end/prompt.js`  
**Cosa rimane fisso**: traccia, LLM, UML atteso (config.js deve rimanere invariato)

```javascript
export const aiProvider = "deepSeek";  // FISSO
export const pdfFile = "Fotografia.pdf";  // FISSO  
export const logFile = "RQ2_PromptV1";
// Modifica prompt.js tra un test e l'altro
// Salva versioni in Prompt/ per tracciare le modifiche
```

### RQ3: Riscrittura Traccia
**Obiettivo**: Migliorare chiarezza della traccia mantenendo la semantica  
**File coinvolti**: `Back-end/RQ3/ErrorReporter.js`, `Traccia/`  
**Cosa cambia**: file PDF della traccia  
**Cosa rimane fisso**: prompt ottimizzato (da `Prompt/PromptFinale.txt`), LLM, UML atteso

```javascript
// Traccia originale
export const pdfFile = "Fotografia.pdf";
export const logFile = "RQ3_TracciaOriginale";

// Traccia chiarificata
export const pdfFile = "Fotografia_Modificata.pdf";
export const logFile = "RQ3_TracciaModificata";
```

### RQ4: Validazione Metriche
**Obiettivo**: Confrontare metriche automatiche con valutazione tradizionale  
**File coinvolti**: `Back-end/RQ4/Voto.js`, `Sperimentazioni/`  
**Modalit√† batch**: analizza tutti gli XMI degli studenti + genera modello LLM

```javascript
export const experiment = "Voto";  // Modalit√† batch
export const directoryCampioni = "../Sperimentazioni/Fotografia";
export const logFile = "RQ4_StudentiVsAI";
```

---

## Descrizione dei Componenti per Cartella

### üìÅ Back-end/LLM/ - Provider di Intelligenza Artificiale
- **Gemini.js**: Integrazione con Google Gemini API
- **OpenRouterIA.js**: Integrazione con OpenRouter per DeepSeek e Meta

### üìÅ Back-end/RQ1/ - Core Components (Research Question 1)
- **Traccia.js**: Estrazione testo da file PDF delle tracce
- **UmlAtteso.js**: Parser e normalizzazione file XMI di riferimento
- **umlComparator.js**: Algoritmi di confronto strutturale tra modelli UML

### üìÅ Back-end/RQ3/ - Error Analysis (Research Question 3)
- **ErrorReporter.js**: Sistema avanzato di classificazione e report errori

### üìÅ Back-end/RQ4/ - Validation (Research Question 4)
- **Voto.js**: Metriche di valutazione e confronto batch studenti vs AI

### üìÅ Prompt/ - Gestione Versioni Prompt
- **PromptFinale.txt**: Versione ottimizzata finale del prompt
- **promptIntermedio.txt**: Versioni di sviluppo e test

---

##  Come leggere e interpretare gli output

###  Posizione dei file di output
Tutti i risultati vengono salvati nella cartella `risultati/` con nomi che includono timestamp:
```
risultati/
‚îú‚îÄ‚îÄ Fotografia.txt_2025-08-26T16-49-28-396+02-00.txt    # Esperimento main
‚îú‚îÄ‚îÄ Fotografia_voto.txt_2025-08-26T17-15-32-123+02-00.txt # Esperimento Voto
‚îî‚îÄ‚îÄ RQ1_Fotografia_DeepSeek.txt_2025-08-26T18-00-15-456+02-00.txt
```

### Anatomia di un file di output (modalit√† "main")

#### **Sezione 1: Configurazione dell'esperimento**
```
IA UTILIZZATA: DEEPSEEK
esperimento : main
---------------------- Inizio del processo ----------------------
```
**Cosa significa**: Mostra quale AI √® stata usata e quale tipo di esperimento.

#### **Sezione 2: Contenuto della traccia**
```
----------------------primo step stampo il Contenuto del PDF----------------------
Un hackathon, ovvero una "maratona di hacking", √® un evento durante il quale...
üìÑ Contenuto PDF estratto!
```
**Cosa significa**: Il testo estratto dal PDF della traccia che √® stato inviato all'AI.

#### **Sezione 3: Modello di riferimento (Docente)**
```
---------------------- secondo step stampo il Model JSON dell'XMI----------------------
{
  "classes": [
    {
      "name": "Hackathon",
      "attributes": [
        {"name": "sede", "type": null},
        {"name": "titolo", "type": null}
      ],
      "methods": []
    }
  ],
  "relations": [
    {"from": "Organizzatore", "to": "Hackathon", "type": "association", "multiplicity": "1-*"}
  ],
  "enumerations": []
}
```
**Cosa significa**: La rappresentazione JSON del modello UML atteso (quello del docente), estratto dal file XMI.

#### **Sezione 4: Risposta dell'AI**
```
---------------------- terzo step stampo il risultato della IA----------------------
{
  "classes": [
    {
      "name": "Hackathon",
      "attributes": [
        {"name": "titolo", "type": "String"},
        {"name": "sede", "type": "String"}
      ]
    }
  ],
  "relations": [],
  "enumerations": []
}
```
**Cosa significa**: Il modello JSON generato dall'AI a partire dalla traccia PDF.

#### **Sezione 5: Risultati del confronto**
```
---------------------- quinto step stampo il risultato del confronto tra i due modelli----------------------
Similarit√† totale: 0.706
Dettagli: {"classSimilarity":0.723,"attributeSimilarity":0.53,"methodSimilarity":0.625,"relationSimilarity":0.929}
Classi abbinate: [{"from":"Hackathon","to":"Hackathon","similarity":1}]
```

**Come interpretare i numeri**:
- **Similarit√† totale**: Punteggio finale da 0 a 1 (70.6% in questo esempio)
  - 0.0-0.3: Modello molto diverso
  - 0.3-0.6: Modello parzialmente corretto
  - 0.6-0.8: Modello buono con alcune lacune
  - 0.8-1.0: Modello molto simile al riferimento

- **Dettagli per componente**:
  - `classSimilarity`: Quanto sono simili le classi (nomi e struttura)
  - `attributeSimilarity`: Quanto sono simili gli attributi
  - `methodSimilarity`: Quanto sono simili i metodi
  - `relationSimilarity`: Quanto sono simili le relazioni tra classi

#### **Sezione 6: Analisi degli errori**
```
==================== REPORT ERRORI ====================
Similarit√†: 70.6% - Status: MEDIO
Errori attendibili: 12
Errori non attendibili: 23

üî¥ ERRORI CRITICI (5):
1. Classe mancante: UtenteRegistrato (CRITICO)
2. Relazione mancante: Team -> Utente (CRITICO)

üü† ERRORI IMPORTANTI (4):
3. Attributo mancante: Hackathon.numeroMassimoDiIscrizioni (IMPORTANTE)

üü° ERRORI MINORI (3):
6. Differenza naming: teamId vs team_id (MINORE)
```

**Come interpretare**:
- **Errori CRITICI**: Mancano elementi fondamentali del dominio
- **Errori IMPORTANTI**: Mancano dettagli significativi ma non essenziali
- **Errori MINORI**: Differenze di stile o naming
- **Errori NON ATTENDIBILI**: Potrebbero essere falsi positivi

#### **Sezione 7: Differenze dettagliate**
```
---------------------- DIFFERENZE DETTAGLIATE ----------------------
Classi mancanti: ["UtenteRegistrato", "Giudice"]
Classi extra: ["Utente"]
Attributi mancanti: [{"classe":"Hackathon","attributo":"numeroMassimoDiIscrizioni"}]
Relazioni mancanti: [{"from":"Team","to":"Utente","type":"association"}]
```

**Uso pratico**: Queste liste ti dicono esattamente cosa √® stato omesso o aggiunto dall'AI rispetto al modello atteso.

#### **Sezione 8: Codice PlantUML**
```
---------------------- GENERAZIONE PLANTUML ----------------------
--- PLANTUML MODELLO ATTESO ---
@startuml
class Hackathon {
  +sede: String
  +titolo: String
}
class Organizzatore
Organizzatore --> Hackathon
@enduml

--- PLANTUML MODELLO IA ---
@startuml
class Hackathon {
  +titolo: String
  +sede: String
}
@enduml
```

**Come usarlo**: Copia questi codici su [PlantUML Online](https://www.plantuml.com/plantuml/uml/) per visualizzare i diagrammi.

###  Anatomia di un file di output (modalit√† "Voto")

La modalit√† Voto produce output pi√π lunghi perch√© analizza tutti i file degli studenti:

```
========== INIZIO ANALISI VOTO ==========
{modello studente in formato JSON}
Similarit√† voto (SimilaritaNumeroErrori): 3
Similarit√† voto (UMLComparator): 0.79


========== FILE ANALIZZATO: 5311.xmi ==========
{modello studente in formato JSON}
Similarit√† voto (SimilaritaNumeroErrori): 3
Similarit√† voto (UMLComparator): 0.79

========== FILE ANALIZZATO: 5321.xmi ==========
{altro modello studente}
Similarit√† voto (SimilaritaNumeroErrori): 5
Similarit√† voto (UMLComparator): 0.45

...

Media Similarit√† voto (SimilaritaNumeroErrori): 3.2
Media Similarit√† voto (UMLComparator): 0.67

========== MODELLO IA GENERATO ==========
{modello generato dall'AI}
Similarit√† voto IA (SimilaritaNumeroErrori): 2
Similarit√† voto IA (UMLComparator): 0.83
```

il primo modello √® sempre l'UML atteso

### 8.4 Metriche: cosa significano i numeri

#### **UMLComparator (0.0 - 1.0)**
- Misura la **similarit√† strutturale complessiva**
- Formula: 40% classi + 20% attributi + 20% metodi + 20% relazioni
- **Esempio**: 0.706 = 70.6% di similarit√†

#### **SimilaritaNumeroErrori (0 - 7)**
- Conta il **numero di categorie di errore** presenti
- **Categorie**: Classi, Attributi, Associazioni, Molteplicit√†, Enumerazioni, Generalizzazioni, Attributo id
- **Esempio**: 3 = errori in 3 categorie su 7

**Relazione tra le metriche**:
- **UMLComparator alto + SimilaritaNumeroErrori basso**: Modello molto buono
- **UMLComparator basso + SimilaritaNumeroErrori alto**: Modello con molti problemi
- **UMLComparator alto + SimilaritaNumeroErrori alto**: Struttura buona ma omissioni localizzate
- **UMLComparator basso + SimilaritaNumeroErrori basso**: Errori diffusi ma non categoriali

---

## Interpretazione dei Risultati

### File di Output (`risultati/`)
I log vengono salvati con timestamp, esempio: `Fotografia.txt_2025-08-26T16-49-28-396+02-00.txt`

- **Errori attendibili vs non attendibili**: Distinzione tra errori reali e possibili falsi positivi

### Sezioni Importanti nei Log
1. **Contenuto PDF**: Testo estratto dalla traccia
2. **Modello atteso**: JSON del docente (da XMI)
3. **Modello generato**: JSON dell'AI
4. **Confronto dettagliato**: Classi/attributi/relazioni mancanti/extra
5. **PlantUML**: Codice per visualizzare i diagrammi

### Comandi Utili per Analisi
```bash
# Estrai tutte le similarit√†
grep "Similarit√† totale:" risultati/*.txt

# Conta errori per categoria  
grep "SimilaritaNumeroErrori" risultati/*_voto.txt

# Trova classi mancanti comuni
grep "Classi mancanti:" risultati/RQ1_*.txt
```

---

## Casi di Studio Disponibili

Il sistema include 5 tracce di complessit√† crescente:

| Traccia | Complessit√† | Descrizione | Risultati Tipici (Gemini) |
|---------|-------------|-------------|---------------------------|
| **ToDo.pdf** | Bassa | Gestione semplice attivit√† | ~0.90 similarit√† |
| **Fotografia.pdf** | Media | Album fotografici con utenti | ~0.85 similarit√† |
| **Hackathon.pdf** | Media-Alta | Team, partecipanti, giudici | ~0.75 similarit√† |
| **Aeroporto.pdf** | Alta | Voli, passeggeri, equipaggi | ~0.60 similarit√† |
| **Autobus.pdf** | Validazione | Confronto con studenti | Media studenti: 0.78 |

**Come aggiungere nuove tracce**:
1. Aggiungi `NuovaTraccia.pdf` in `Traccia/`
2. Aggiungi `NuovaTraccia.xmi` in `UmlAtteso/`
3. (Opzionale) Crea `Sperimentazioni/NuovaTraccia/` con XMI degli studenti

---
## Metriche di Valutazione SPOSTARE
- **UMLComparator**: similarit√† strutturale (0.0-1.0) - 40% classi + 20% attributi + 20% metodi + 20% relazioni
- **SimilaritaNumeroErrori**: conteggio categorie di errore (0-7) - Classi, Attributi, Associazioni, Molteplicit√†, Enumerazioni, Generalizzazioni, Attributi ID


## Troubleshooting & FAQ

### Problemi Comuni

| Problema | Causa | File Coinvolto | Soluzione |
|----------|-------|----------------|-----------|
| **Similarit√† = 0** | Nessuna classe matchata | `RQ1/umlComparator.js` | Verifica percorsi PDF/XMI, controlla nomi classi |
| **Errore API** | Chiave mancante/invalida | `LLM/*.js`, `.env` | Controlla `.env`, verifica quota API |
| **Log vuoto (modalit√† Voto)** | Cartella studenti vuota | `RQ4/Voto.js` | Verifica `directoryCampioni` e presenza file .xmi |
| **JSON malformato** | Risposta AI corrotta | `LLM/*.js` | Riprova, il sistema ha fallback automatici |
| **Timeout** | Rate limiting API | `LLM/*.js` | Aspetta qualche minuto e riprova |
| **Percorso non trovato** | Struttura cartelle errata | `config.js` | Verifica percorsi relativi corretti |

### Struttura Cartelle per Debug
```bash
# Verifica struttura corretta
ls -la Back-end/LLM/          # Deve contenere Gemini.js, OpenRouterIA.js
ls -la Back-end/RQ1/          # Deve contenere Traccia.js, UmlAtteso.js, umlComparator.js  
ls -la Back-end/RQ3/          # Deve contenere ErrorReporter.js
ls -la Back-end/RQ4/          # Deve contenere Voto.js
ls -la Traccia/               # Deve contenere i PDF
ls -la UmlAtteso/             # Deve contenere gli XMI di riferimento
ls -la Sperimentazioni/       # Deve contenere cartelle per traccia con XMI studenti
```

### FAQ

**Q: Quale LLM funziona meglio?**  
A: Gemini > DeepSeek > Meta (ma dipende dalla traccia)

**Q: Come interpreto "Errori non attendibili"?**  
A: Sono possibili falsi positivi, concentrati sugli "Errori attendibili"

**Q: Posso modificare le soglie delle metriche?**  
A: S√¨, nei file `umlComparator.js` e `Voto.js`

**Q: Come visualizzo i diagrammi?**  
A: Copia il codice PlantUML dai log su [plantuml.com](https://www.plantuml.com/plantuml/uml/)

**Q: Dove trovo il codice per una specifica Research Question?**  
A: RQ1‚Üí`Back-end/RQ1/`, RQ2‚Üí`Back-end/prompt.js`, RQ3‚Üí`Back-end/RQ3/`, RQ4‚Üí`Back-end/RQ4/`

**Q: Come aggiungo un nuovo provider LLM?**  
A: Crea un nuovo file in `Back-end/LLM/` seguendo il pattern di `Gemini.js`

**Q: Dove modifico i criteri di valutazione?**  
A: Metriche in `RQ1/umlComparator.js` e `RQ4/Voto.js`, classificazione errori in `RQ3/ErrorReporter.js`

---

## Sviluppo e Manutenzione

### üèóÔ∏è Aggiungere una nuova Research Question
1. Crea cartella `Back-end/RQ{N}/`
2. Implementa la logica specifica
3. Integra in `index.js` 
4. Aggiorna `config.js` se necessario

### ü§ñ Aggiungere un nuovo LLM Provider
1. Crea `Back-end/LLM/NuovoProvider.js`
2. Implementa metodi standard (`runModel`, gestione errori)
3. Aggiungi switch case in `index.js`
4. Aggiorna `config.js` con nuovo provider

### üìä Modificare le Metriche
- **Similarit√† strutturale**: modifica `RQ1/umlComparator.js`
- **Conteggio errori**: modifica `RQ4/Voto.js`  
- **Classificazione errori**: modifica `RQ3/ErrorReporter.js`

---

---

## Troubleshooting

| Problema | Soluzione |
|----------|-----------|
| Similarit√† = 0 | Verificare percorsi PDF/XMI |
| Errore API | Controllare chiavi in `.env` |
| Log vuoto | Verificare `directoryCampioni` |
